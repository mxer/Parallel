\documentclass{article}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage{url}
\usepackage{geometry}%
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\makeatletter
\def\BState{\State\hskip-\ALG@thistlm}
\makeatother

\begin{document}
	\title{Parallel Processing Report}
	\maketitle
	\section{Problem Definition}
		With the digitization of many medical devices, the images generated have grown higher in resolution and larger in quantity. MRI machines, produce a sequence that contains several hundred high resolution images, each image representing a slice of the tissue being filmed. Processing such sequences requires extensive computation. One of the most common processing procedures is to cluster the sequence of images in 3D, that is, connect different clusters that exist in each slice, with ones that exist in the next slice, which then would correspond to, for example, segmenting a muscle or bone in 3D. Doing such computations on one processor takes a significant amount of time. In this article, we explore a method to approach this task on a multi-core architecture.
	\section{Proposed Algorithm}\label{sec:alg}
		A common approach to solving the problem of detecting 3D clutsres is to divide the problem into two parts, generate clusters on each image separately, then connect these clusters accross images. This solution is map-reduce compatible. Following this approach, we have divided the problem into two subtasks:
		\begin{enumerate}
			\item Generate clusters on each image. (Map) \label{task:1}
			\item Merge clusters of consequtive images. (Reduce) \label{task:2}
		\end{enumerate}
		\subsection{Generate clusters on each image}
			Generating clusters on one image is independent of all the other images. Therefore, this is an embarassingly parallel task, where we distribute the slices in an ordered fashion over the available cores, a chunk of images per core, where each chunk is $N/P$ where $N$ is the slice count and $P$ the processor count. Then each core computes a sequential K-means on its designated slices. This can be seen in details in Procedure \textit{Cluster} in Algorithm~\ref{algo}.
		\subsection{Merge clusters of consequtive images}
			The clusters that were generated in the previous step are then combined together into one set of clusters. This has to be done sequentially in order to maintain stability in the labels. This sequential merging was achieved by having each processor merge the labels of its preceding processor, and send its new set of labels to the following processor. This can be seen in details in Procedure \textit{Merge} in Algorithm~\ref{algo}.
		\begin{algorithm}
			\caption{3D K-means}\label{algo}
			\begin{algorithmic}[1]
				\Procedure{Cluster}{}
				\State $N \gets$ number of Images
				\State $P \gets$ number of Processors
				\State $p \gets$ processor Id
				\State $\textit{p\_images} \gets $images[range($p*(N/P), (p+1)*(N/P))$]$ $
				\For{$i$ in 0, length($p\_images$)}
				\State $labels[i] \gets$ k\_means(\textit{p\_images}[i])
				\State $blobs[i] \gets$ connected\_components($p\_images[i], labels[i]$)
				\EndFor
			
				\EndProcedure
				
				\Procedure{Merge}{}
				\State $c\_blobs \gets$ combine\_blobs($blobs[0], blobs$)
				\If {$p~!=0$}
					\State receive($previous\_blobs$)
					\State combine\_blobs($blobs, previous\_blobs$)\\
				\EndIf
					\State send($p+1, c\_blobs$)
				\EndProcedure
				\Procedure{combine\_blobs}{blobs, blobs\_list}
				\State $intersections \gets$ intersect\_blobs\_rectangle($blobs, blobs\_list$)
				\For{$i$ in 0, length($intersections$)}
					\State $new\_blobs \gets blobs[intersections[i]]$
				\EndFor
				\EndProcedure
			\end{algorithmic}
		\end{algorithm}
		
		
	\section{Theoretical Performance Analysis}
		We define the time complexity in terms of number of images processed per unit time. For Task~\ref{task:1}, the complexity of the algorithm for the sequential version is $O(N)$. Since the task is embarassingly parallel, the complexity is $O(N/P)$ for the parallel version. For Task~2, the complexity of the algorithm is again $O(N)$, and for the parallel version, its the same.
	
\end{document}